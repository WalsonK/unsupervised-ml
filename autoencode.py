import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split


class FullScratchAutoencoder:
    def __init__(self, input_dim, encoding_dim, learning_rate=0.01, epochs=100):
        self.input_dim = input_dim
        self.encoding_dim = encoding_dim
        self.learning_rate = learning_rate
        self.epochs = epochs

        # Initialisation des poids (Xavier/Glorot)
        self.W_encoder = np.random.randn(input_dim, encoding_dim) * np.sqrt(2.0 / input_dim)
        self.b_encoder = np.zeros((1, encoding_dim))

        self.W_decoder = np.random.randn(encoding_dim, input_dim) * np.sqrt(2.0 / encoding_dim)
        self.b_decoder = np.zeros((1, input_dim))

        # Historique d'entra√Ænement
        self.train_loss_history = []
        self.val_loss_history = []

    def sigmoid(self, x):
        """Fonction d'activation sigmoid avec clipping pour √©viter l'overflow"""
        x = np.clip(x, -500, 500)
        return 1 / (1 + np.exp(-x))

    def sigmoid_derivative(self, x):
        """D√©riv√©e de la fonction sigmoid"""
        return x * (1 - x)

    def encode(self, X):
        """Encodage: X -> espace latent"""
        z = np.dot(X, self.W_encoder) + self.b_encoder
        return self.sigmoid(z)

    def decode(self, encoded):
        """D√©codage: espace latent -> X"""
        z = np.dot(encoded, self.W_decoder) + self.b_decoder
        return self.sigmoid(z)

    def forward(self, X):
        """Passe avant compl√®te"""
        encoded = self.encode(X)
        decoded = self.decode(encoded)
        return encoded, decoded

    def compute_loss(self, X, X_reconstructed):
        """Calcul de la perte (MSE)"""
        return np.mean((X - X_reconstructed) ** 2)

    def fit(self, X_train, X_val=None, verbose=True):
        """
        Entra√Ænement de l'autoencoder

        Args:
            X_train: Donn√©es d'entra√Ænement
            X_val: Donn√©es de validation (optionnel)
            verbose: Afficher le progr√®s
        """
        if verbose:
            print(f"üîÑ Entra√Ænement de l'autoencoder ({self.epochs} epochs)...")
            print(f"   ‚Ä¢ Dimension d'entr√©e: {self.input_dim}")
            print(f"   ‚Ä¢ Dimension d'encodage: {self.encoding_dim}")
            print(f"   ‚Ä¢ Taux d'apprentissage: {self.learning_rate}")

        for epoch in range(self.epochs):
            # Passe avant
            encoded, decoded = self.forward(X_train)

            # Calcul de la perte
            train_loss = self.compute_loss(X_train, decoded)
            self.train_loss_history.append(train_loss)

            # Passe arri√®re (backpropagation)
            m = X_train.shape[0]

            # Erreur de sortie
            output_error = decoded - X_train

            # Gradients pour le d√©codeur
            dW_decoder = np.dot(encoded.T, output_error) / m
            db_decoder = np.sum(output_error, axis=0, keepdims=True) / m

            # Erreur propag√©e vers l'encodeur
            hidden_error = np.dot(output_error, self.W_decoder.T) * self.sigmoid_derivative(encoded)

            # Gradients pour l'encodeur
            dW_encoder = np.dot(X_train.T, hidden_error) / m
            db_encoder = np.sum(hidden_error, axis=0, keepdims=True) / m

            # Mise √† jour des poids
            self.W_decoder -= self.learning_rate * dW_decoder
            self.b_decoder -= self.learning_rate * db_decoder
            self.W_encoder -= self.learning_rate * dW_encoder
            self.b_encoder -= self.learning_rate * db_encoder

            # Validation
            if X_val is not None:
                _, val_decoded = self.forward(X_val)
                val_loss = self.compute_loss(X_val, val_decoded)
                self.val_loss_history.append(val_loss)

            # Affichage du progr√®s
            if verbose and (epoch + 1) % 10 == 0:
                val_msg = f", Val Loss: {val_loss:.6f}" if X_val is not None else ""
                print(f"   Epoch {epoch + 1:3d}/{self.epochs} - Train Loss: {train_loss:.6f}{val_msg}")

        if verbose:
            print("‚úÖ Entra√Ænement termin√©!")
        return self

    def compress(self, X):
        """Compression: √©quivalent √† encode"""
        return self.encode(X)

    def decompress(self, encoded):
        """D√©compression: √©quivalent √† decode"""
        return self.decode(encoded)

    def reconstruct(self, X):
        """Reconstruction compl√®te"""
        _, decoded = self.forward(X)
        return decoded